# NeurIPS 2026 Submission Plan

**Target**: NeurIPS 2026 Main Conference
**Strategy**: ICLR 2026 Workshop â†’ í”¼ë“œë°± â†’ NeurIPS 2026
**í˜„ì¬ ì˜ˆìƒ ê°€ëŠ¥ì„±**: 30-40% (ë³´ê°• í›„ 50-60%)

---

## íƒ€ì„ë¼ì¸

| ì‹œê¸° | ì‘ì—… | ìƒíƒœ |
|------|------|------|
| **Jan 2026** | ICLR workshop CFP í™•ì¸ ë° ì„ íƒ | â³ |
| **Feb 2026** | ICLR Workshop paper ì œì¶œ (4-6p) | â³ |
| **Apr 2026** | ICLR Workshop ë°œí‘œ + í”¼ë“œë°± | â³ |
| **May 2026** | NeurIPS 2026 ì œì¶œ | â³ |
| **Camera-ready** | Open source package | â³ |

---

## í˜„ì¬ ìƒíƒœ (2025-12-08 ê¸°ì¤€)

### í•µì‹¬ ë°œê²¬: Error Propagation Hypothesis
FK Attributionì€ **error propagation** êµ¬ì¡°ê°€ ìˆëŠ” ë„ë©”ì¸ì—ì„œë§Œ ìœ íš¨:
- **SALT (ERP)**: Ï = 1.000 âœ…
- **Trial (Clinical)**: Ï = 1.000 âœ…
- **Avito (Classifieds)**: Ï = 1.000 âœ…
- **Stack (Q&A)**: Ï = -0.500 âŒ (ì˜ˆìƒëŒ€ë¡œ ì‹¤íŒ¨)

### ì™„ë£Œëœ ê²ƒ âœ…
- [x] RelUQ Framework ì •ì˜ (Algorithm, I/O, Theory claims)
- [x] **Attribution-Error Validation** (THE KEY RESULT)
- [x] **Error Propagation Hypothesis** ë°œê²¬ ë° ê²€ì¦
- [x] Multi-domain validation (SALT, Trial, Avito, Stack)
- [x] **SHAP baseline ë¹„êµ** - FK groupingì´ í•µì‹¬, ë°©ë²•ì€ ë¬´ê´€
- [x] **InfoSHAP-style baseline** - ì§ì ‘ MI ì‹¤íŒ¨, Permutation ì„±ê³µ
- [x] LaTeX draft (Abstract, Introduction, Experiments, Conclusion)
- [x] Ablation study (K, P, n, subsample rate)

### ë¶€ì¡±í•œ ê²ƒ (NeurIPS í•„ìˆ˜ ë³´ê°•) âš ï¸
- [ ] **MC Dropout ê²€ì¦** - "UQ method-agnostic" ì£¼ì¥ í•„ìš”
- [ ] **Intervention study** - ì‹¤ì œ FK ê°œì„  â†’ ë¶ˆí™•ì‹¤ì„± ê°ì†Œ ì¦ëª…
- [ ] Domain ì¶”ê°€ (5ê°œ ì´ìƒ ê¶Œì¥)
- [ ] Scale up (10K+ samples)
- [ ] Figure ìƒì„±

---

## NeurIPS ìˆ˜ë½ì„ ìœ„í•œ í•µì‹¬ ì•½ì  ë¶„ì„

### 1. Method Generality (ê°€ì¥ í° ì•½ì ) ğŸ”´

**í˜„ì¬ ìƒíƒœ:**
```
LightGBM Ensembleë§Œ ê²€ì¦
```

**ë¦¬ë·°ì–´ ì˜ˆìƒ ì§ˆë¬¸:**
> "This only works with tree ensembles. Does it generalize to neural networks?
> What about MC Dropout, Deep Ensembles, or Conformal Prediction?"

**í•„ìš”í•œ ë³´ê°•:**
- [ ] MC Dropout (MLP) ê²€ì¦ - 1ì£¼
- [ ] Deep Ensemble (NN) ê²€ì¦ - ì„ íƒ
- ìµœì†Œ 2ê°œ ë‹¤ë¥¸ UQ ë°©ë²•ì—ì„œ ë™ì¼ ê²°ê³¼ í•„ìš”

**ë³´ê°• í›„ ë‹µë³€:**
> "FK Attribution achieves Ï â‰¥ 0.90 with both tree ensembles AND neural networks with MC Dropout,
> demonstrating that our method is UQ-agnostic."

---

### 2. Real-World Impact (ì‹¤ìš©ì„± ì¦ëª… ë¶€ì¡±) ğŸ”´

**í˜„ì¬ ìƒíƒœ:**
```
"FK Attribution â†’ ë°ì´í„° í’ˆì§ˆ ê°œì„  ê°€ëŠ¥" (ì£¼ì¥ë§Œ, ì¦ê±° ì—†ìŒ)
```

**ë¦¬ë·°ì–´ ì˜ˆìƒ ì§ˆë¬¸:**
> "Can you show that improving the identified FK actually reduces uncertainty?
> Where's the causal evidence?"

**í•„ìš”í•œ ë³´ê°•:**
- [ ] Intervention study - 2ì£¼
  ```python
  # 1. í˜„ì¬ ë¶ˆí™•ì‹¤ì„± ì¸¡ì •
  baseline_unc = measure_uncertainty(X)

  # 2. ê°€ì¥ ì¤‘ìš”í•œ FK ë°ì´í„° í’ˆì§ˆ "ê°œì„ " ì‹œë®¬ë ˆì´ì…˜
  X_improved = reduce_noise(X, fk_group="ITEM")

  # 3. ê°œì„  í›„ ë¶ˆí™•ì‹¤ì„± ê°ì†Œ í™•ì¸
  improved_unc = measure_uncertainty(X_improved)

  # â†’ "FK Attributionì´ ì˜¬ë°”ë¥¸ íƒ€ê²Ÿì„ ì§€ëª©í–ˆë‹¤" ì¦ëª…
  ```

**ë³´ê°• í›„ ë‹µë³€:**
> "We demonstrate that reducing noise in the top-attributed FK group (ITEM)
> leads to 23% uncertainty reduction, while improving low-attributed FKs shows no effect."

---

### 3. Theoretical Rigor (ì´ë¡  ê¹Šì´ ë¶€ì¡±) ğŸŸ¡

**í˜„ì¬ ìƒíƒœ:**
```
Error Propagation Hypothesis = ì§ê´€ì  ì„¤ëª…
"FKê°€ DAG êµ¬ì¡°ë©´ ì‘ë™í•œë‹¤"
```

**ë¦¬ë·°ì–´ ì˜ˆìƒ ì§ˆë¬¸:**
> "Where's the formal proof? Under what assumptions does this hold?"

**ì˜µì…˜:**
- Option A: Formal proof ì¶”ê°€ (3-4ì£¼) - ì–´ë ¤ì›€
- Option B: "Empirical study"ë¡œ ëª…í™•íˆ í¬ì§€ì…”ë‹ - ê¶Œì¥

**í¬ì§€ì…”ë‹ ì „ëµ:**
> "We present an empirical study with a testable hypothesis (Error Propagation),
> validated across 4 domains. Formal theoretical analysis is left for future work."

---

### 4. Scale & Domains (ê·œëª¨ ë¶€ì¡±) ğŸŸ¡

**í˜„ì¬ ìƒíƒœ:**
```
3ê°œ EP ë„ë©”ì¸ + 1ê°œ Non-EP
Sample size: 2,000-3,000
```

**ë¦¬ë·°ì–´ ì˜ˆìƒ ì§ˆë¬¸:**
> "Only 3 domains? Sample size too small."

**í•„ìš”í•œ ë³´ê°•:**
- [ ] Sample size 10K+ ì‹¤í—˜ - 1ì¼
- [ ] Domain 1-2ê°œ ì¶”ê°€ (ì„ íƒ)

---

### 5. Novelty Defense (ê¸°ì—¬ ëª…í™•í™”) ğŸŸ¡

**ë¦¬ë·°ì–´ ì˜ˆìƒ ì§ˆë¬¸:**
> "This is just permutation importance + FK grouping. What's new?"

**í˜„ì¬ ë‹µë³€ (ì•½í•¨):**
- FK grouping
- Error Propagation theory

**ê°•í™”ëœ ë‹µë³€:**
1. **FK Grouping = Schema-guided, not data-driven**
   - SHAP + clustering â‰  RelUQ (correlation-based vs schema-based)
2. **Error Propagation Hypothesis = Scope clarification**
   - ì–¸ì œ ì‘ë™í•˜ê³  ì–¸ì œ ì•ˆ ë˜ëŠ”ì§€ ëª…í™•íˆ (ê¸°ì¡´ ë°©ë²•ì— ì—†ìŒ)
3. **Actionability**
   - FK = ë°ì´í„° ì†Œìœ ì â†’ ì‹¤ì œ ê°œì„  ê°€ëŠ¥

---

## ë³´ê°• ìš°ì„ ìˆœìœ„

| ìˆœìœ„ | ì‘ì—… | íš¨ê³¼ | ë…¸ë ¥ | ìƒíƒœ |
|------|------|------|------|------|
| **1** | **MC Dropout ê²€ì¦** | ğŸ”´ ë§¤ìš° ë†’ìŒ | 1ì£¼ | â³ í•„ìˆ˜ |
| **2** | **Intervention study** | ğŸ”´ ë§¤ìš° ë†’ìŒ | 2ì£¼ | â³ í•„ìˆ˜ |
| 3 | Scale up (10K) | ğŸŸ¡ ì¤‘ê°„ | 1ì¼ | â³ ê¶Œì¥ |
| 4 | Domain ì¶”ê°€ | ğŸŸ¡ ì¤‘ê°„ | 1ì£¼ | ì„ íƒ |
| 5 | Formal theory | ğŸŸ¡ ì¤‘ê°„ | 3-4ì£¼ | ì—°ê¸° |

---

## ë³´ê°• í›„ ì˜ˆìƒ ê°€ëŠ¥ì„±

| ì‹œë‚˜ë¦¬ì˜¤ | ê°€ëŠ¥ì„± |
|----------|--------|
| í˜„ì¬ ìƒíƒœ | 30-40% |
| + MC Dropout | 45-50% |
| + MC Dropout + Intervention | **55-65%** |
| + ìœ„ + Domain ì¶”ê°€ | 60-70% |

---

## ë³´ê°• ì‚¬í•­ ìƒì„¸ ê³„íš

### 1. Baseline ì¶”ê°€ (í•„ìˆ˜)

NeurIPS ë¦¬ë·°ì–´ê°€ ë¬¼ì„ ê²ƒ: "ê¸°ì¡´ ë°©ë²•ê³¼ ë¹„êµí–ˆë‚˜?"

#### 1.1 InfoSHAP (NeurIPS 2023)
```
ë…¼ë¬¸: "InfoSHAP: Shapley Values for Information Theoretic Feature Attribution"
ì™œ ë¹„êµí•´ì•¼ í•˜ë‚˜: ê°€ì¥ ìµœì‹  uncertainty attribution ë°©ë²•

êµ¬í˜„ ê³„íš:
1. InfoSHAP ë…¼ë¬¸ ì½ê³  í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ íŒŒì•…
2. ê³µì‹ ì½”ë“œ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì¬êµ¬í˜„
3. ë™ì¼ ë°ì´í„°ì…‹ (rel-f1, rel-stack, rel-amazon)ì— ì ìš©
4. Stability ë¹„êµ (ìš°ë¦¬ vs InfoSHAP)

ì˜ˆìƒ ê²°ê³¼:
- InfoSHAP = feature-level â†’ stability ë‚®ì„ ê²ƒ
- RelUQ > InfoSHAP on stability (ê°€ì„¤)

ì‹¤í—˜ ì½”ë“œ ìœ„ì¹˜: experiments/baselines/infoshap_baseline.py
```

#### 1.2 Permutation Importance (Variance)
```
ë°©ë²•: ê¸°ì¡´ permutation importanceë¥¼ varianceì— ì ìš©
      (prediction ëŒ€ì‹  uncertainty ë³€í™” ì¸¡ì •)

êµ¬í˜„:
- ì´ë¯¸ RelUQì—ì„œ í•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬
- Feature-levelë¡œ ìˆ˜í–‰ í›„ ì§‘ê³„ ë°©ì‹ë§Œ ë‹¤ë¥´ê²Œ

ë¹„êµ:
- Feature-level permutation (24 features) vs FK-level (5 groups)
- ê°™ì€ mechanism, ë‹¤ë¥¸ granularity

ì‹¤í—˜ ì½”ë“œ ìœ„ì¹˜: experiments/baselines/permutation_baseline.py
```

#### 1.3 SHAP Variance Attribution
```
ë°©ë²•: SHAP ê°’ì˜ ë¶„ì‚°ì„ uncertainty attributionìœ¼ë¡œ ì‚¬ìš©
      (InfoSHAPê³¼ ë‹¤ë¥¸ ì ‘ê·¼)

êµ¬í˜„:
- TreeSHAPìœ¼ë¡œ ê° ì˜ˆì¸¡ì˜ SHAP ê³„ì‚°
- SHAP ê°’ë“¤ì˜ ë¶„ì‚° = feature importance for variance

ë¹„êµ:
- SHAP-based vs Permutation-based
- ë‘˜ ë‹¤ feature-level â†’ ë¶ˆì•ˆì • ì˜ˆìƒ

ì‹¤í—˜ ì½”ë“œ ìœ„ì¹˜: experiments/baselines/shap_variance_baseline.py
```

#### 1.4 Data-Driven Grouping (Correlation Clustering)
```
ì´ë¯¸ ì™„ë£Œ: experiment_fk_vs_datadriven_f1.py

ì¶”ê°€ í•„ìš”:
- rel-stack, rel-amazonì—ë„ ë™ì¼ ì‹¤í—˜
- ë…¼ë¬¸ìš© í…Œì´ë¸” ì •ë¦¬
```

### 2. Ablation Study (í•„ìˆ˜)

NeurIPS ë¦¬ë·°ì–´ê°€ ë¬¼ì„ ê²ƒ: "í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ë¯¼ê°í•˜ì§€ ì•Šë‚˜?"

#### 2.1 Ensemble Size (K) ë¯¼ê°ë„
```
ì‹¤í—˜:
- K = {3, 5, 7, 10, 15, 20}
- ê° Kì—ì„œ attribution ê³„ì‚°
- Stability ì¸¡ì •

ì˜ˆìƒ:
- K=3: ë†’ì€ variance (ë¶ˆì•ˆì •)
- K=5: sweet spot (í˜„ì¬ ì‚¬ìš©)
- K=10+: diminishing returns

ë„í‘œ: Line plot (K vs Stability)
```

#### 2.2 Permutation Runs (P) ë¯¼ê°ë„
```
ì‹¤í—˜:
- P = {1, 3, 5, 10, 20}
- ê° Pì—ì„œ attribution ê³„ì‚°
- Stabilityì™€ ê³„ì‚° ì‹œê°„ ì¸¡ì •

ì˜ˆìƒ:
- P=1: ë†’ì€ variance
- P=5: ì¶©ë¶„íˆ ì•ˆì • (í˜„ì¬ ì‚¬ìš©)
- P=10+: ê±°ì˜ ì°¨ì´ ì—†ìŒ

ë„í‘œ: Line plot (P vs Stability) + computation time
```

#### 2.3 Sample Size Scaling
```
ì‹¤í—˜:
- n = {500, 1000, 2000, 3000, 5000, 10000}
- ê° nì—ì„œ attribution ê³„ì‚°
- Top FK ì¼ê´€ì„± ë° stability ì¸¡ì •

ì˜ˆìƒ:
- n < 1000: ë¶ˆì•ˆì •
- n >= 2000: ì•ˆì •ì  ìˆ˜ë ´

ë„í‘œ:
- Line plot (n vs Stability)
- Heatmap (FK attribution % across n)
```

#### 2.4 Subsampling Rate ë¯¼ê°ë„
```
ì‹¤í—˜:
- subsample = {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}
- colsample = {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}

ì˜ˆìƒ:
- rate=1.0: ensemble ë‹¤ì–‘ì„± ë¶€ì¡± â†’ variance â‰ˆ 0
- rate=0.8: ì ì ˆí•œ ë‹¤ì–‘ì„± (í˜„ì¬ ì‚¬ìš©)
- rate=0.5: ë„ˆë¬´ ì ì€ ë°ì´í„° â†’ ë¶ˆì•ˆì •

ë„í‘œ: Heatmap (subsample Ã— colsample â†’ Stability)
```

### 3. Theoretical Contribution (ì¤‘ìš”)

NeurIPS ë¦¬ë·°ì–´ê°€ ë¬¼ì„ ê²ƒ: "ì´ë¡ ì  ê¸°ì—¬ê°€ ë­ëƒ?"

#### 3.1 Variance Reduction Bound
```
ëª©í‘œ: FK groupingì´ feature-level ëŒ€ë¹„ varianceë¥¼ ì¤„ì¸ë‹¤ëŠ” ê²ƒì„ ì¦ëª…

Theorem (Draft):
Let X = [X_1, ..., X_n] be features with FK-induced correlation structure.
Let G = {g_1, ..., g_k} be FK groups where features within g_i are correlated.
Then for permutation-based attribution:

Var[Î±_FK(g_i)] â‰¤ (1/|g_i|) * Î£_{f âˆˆ g_i} Var[Î±_feature(f)]

ì¦‰, FK-level variance â‰¤ feature-level varianceì˜ í‰ê· 

ì¦ëª… ì•„ì´ë””ì–´:
- Within-group correlation â†’ attribution ë¶„ì‚°ì´ ê·¸ë£¹ ë‚´ì—ì„œ ê³µìœ ë¨
- ê·¸ë£¹ìœ¼ë¡œ ì§‘ê³„ â†’ ë¶„ì‚°ì˜ í•©ì´ ì•„ë‹Œ í‰ê· 

í•„ìš” ì‘ì—…:
1. Correlation structureë¥¼ formalí•˜ê²Œ ì •ì˜
2. Permutation attributionì˜ variance ë¶„ì„
3. Groupingì˜ íš¨ê³¼ë¥¼ boundë¡œ í‘œí˜„
```

#### 3.2 Stability Guarantee
```
ëª©í‘œ: íŠ¹ì • ì¡°ê±´ í•˜ì—ì„œ stability â‰¥ threshold ë³´ì¥

Proposition:
If within-group correlation Ï_within > Ï_between (between-group correlation),
then FK grouping achieves stability Ï â‰¥ f(Ï_within, Ï_between, k)
where k is number of groups.

ì¦ëª… ì•„ì´ë””ì–´:
- High within-group correlation â†’ ê·¸ë£¹ ë‚´ featureë“¤ì´ í•¨ê»˜ ì›€ì§ì„
- Low between-group correlation â†’ ê·¸ë£¹ ê°„ ë…ë¦½ì 
- ë”°ë¼ì„œ attributionì´ ì•ˆì •ì 
```

#### 3.3 Actionability Formalization (Optional)
```
Actionabilityë¥¼ formalí•˜ê²Œ ì •ì˜í•˜ê¸° ì–´ë ¤ì›€
ëŒ€ì•ˆ: Case studyë¡œ qualitativeí•˜ê²Œ ë³´ì—¬ì£¼ê¸°
```

### 4. ëŒ€ê·œëª¨ ì‹¤í—˜ (ê¶Œì¥)

NeurIPS ë¦¬ë·°ì–´ê°€ ë¬¼ì„ ê²ƒ: "ë” í° ë°ì´í„°ì—ì„œë„ ë˜ë‚˜?"

#### 4.1 Larger Sample Sizes
```
í˜„ì¬: n=3000
ëª©í‘œ: n=10000, n=50000 (ê°€ëŠ¥í•˜ë©´)

ì£¼ì˜:
- rel-amazon: 20M reviews â†’ sampling í•„ìš”
- ê³„ì‚° ì‹œê°„ ì¦ê°€ â†’ caching í•„ìˆ˜

ì˜ˆìƒ ê²°ê³¼:
- Stability ìœ ì§€ ë˜ëŠ” í–¥ìƒ
- Top FK ì¼ê´€ì„± ìœ ì§€
```

#### 4.2 More Datasets (Optional)
```
RelBench ì¶”ê°€ ë°ì´í„°ì…‹:
- rel-avito (Classifieds)
- rel-hm (Fashion retail)
- rel-event (Event recommendation)
- rel-trial (Clinical trials)

ìš°ì„ ìˆœìœ„:
1. rel-hm: ë¦¬í…Œì¼ ë„ë©”ì¸, e-commerceì™€ ë¹„êµ
2. rel-trial: í—¬ìŠ¤ì¼€ì–´ ë„ë©”ì¸, ë‹¤ì–‘ì„± í™•ë³´
```

#### 4.3 Failure Case Analysis
```
ì–¸ì œ RelUQê°€ ì‹¤íŒ¨í•˜ëŠ”ê°€?

ê°€ì„¤:
- FK groupsê°€ ë„ˆë¬´ ì ì„ ë•Œ (k < 3)
- FK groups í¬ê¸°ê°€ ê·¹ë„ë¡œ ë¶ˆê· í˜•í•  ë•Œ
- Within-group correlationì´ ë‚®ì„ ë•Œ

ì‹¤í—˜:
- ì˜ë„ì ìœ¼ë¡œ failure ì¡°ê±´ ë§Œë“¤ê¸°
- Synthetic dataë¡œ boundary í…ŒìŠ¤íŠ¸
```

### 5. ë…¼ë¬¸ ì‘ì„± (í•„ìˆ˜)

#### 5.1 Figure ì œì‘
```
í•„ìˆ˜ Figures:
1. Overview diagram: RelUQ pipeline (Input â†’ FK mapping â†’ Ensemble â†’ Attribution)
2. Stability comparison: Bar chart (RelUQ vs baselines)
3. Ablation plots: K, P, n sensitivity
4. Multi-domain results: Table or grouped bar chart

Optional:
5. Case study drill-down: DRIVER â†’ specific features â†’ entities
6. Correlation heatmap: FK groups vs random groups
```

#### 5.2 Writing
```
Sectionë³„ ë¶„ëŸ‰ (NeurIPS 8 pages):
- Abstract: 150 words
- Introduction: 1 page
- Related Work: 0.5 page
- Method: 1.5 pages (Algorithm + Theory)
- Experiments: 3 pages (Tables + Figures + Analysis)
- Conclusion: 0.5 page
- References: ë³„ë„

Appendix (supplementary):
- Full proofs
- Additional experiments
- Implementation details
```

---

## íƒ€ì„ë¼ì¸ (4ê°œì›”)

### Month 1 (Dec 2025)
```
Week 1-2: Baselines êµ¬í˜„ ë° ì‹¤í—˜
  - [ ] InfoSHAP êµ¬í˜„/ì ìš©
  - [ ] Permutation baseline
  - [ ] SHAP variance baseline
  - [ ] Correlation clustering (3 datasets)

Week 3-4: Ablation study
  - [ ] K sensitivity
  - [ ] P sensitivity
  - [ ] n scaling
  - [ ] Subsampling rate
```

### Month 2 (Jan 2026)
```
Week 1-2: Theory ê°•í™”
  - [ ] Variance reduction bound ì¦ëª…
  - [ ] Stability guarantee ì¦ëª…
  - [ ] ì§€ë„êµìˆ˜ ê²€í† 

Week 3-4: ëŒ€ê·œëª¨ ì‹¤í—˜
  - [ ] n=10000 ì‹¤í—˜
  - [ ] ì¶”ê°€ ë°ì´í„°ì…‹ (rel-hm)
  - [ ] Failure case ë¶„ì„
```

### Month 3 (Feb 2026)
```
Week 1-2: ë…¼ë¬¸ ì‘ì„±
  - [ ] Method section ì™„ì„±
  - [ ] Experiments section ì™„ì„±
  - [ ] Figures ì œì‘

Week 3-4: ë…¼ë¬¸ ì‘ì„± ê³„ì†
  - [ ] Introduction ë‹¤ë“¬ê¸°
  - [ ] Related work ì™„ì„±
  - [ ] Abstract ìµœì¢…í™”
```

### Month 4 (Mar 2026)
```
Week 1-2: ë¦¬ë·° ë° ìˆ˜ì •
  - [ ] ì§€ë„êµìˆ˜ ë¦¬ë·°
  - [ ] ë™ë£Œ ë¦¬ë·°
  - [ ] í”¼ë“œë°± ë°˜ì˜

Week 3-4: ìµœì¢… ì¤€ë¹„
  - [ ] Camera-ready í’ˆì§ˆ ì²´í¬
  - [ ] Supplementary ì¤€ë¹„
  - [ ] ì œì¶œ
```

---

## íŒŒì¼ êµ¬ì¡° ê³„íš

```
ai-in-finance/
â”œâ”€â”€ paper/
â”‚   â”œâ”€â”€ main.tex                    # ë©”ì¸ ë…¼ë¬¸
â”‚   â”œâ”€â”€ supplementary.tex           # ë¶€ë¡
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ overview.pdf
â”‚   â”‚   â”œâ”€â”€ stability_comparison.pdf
â”‚   â”‚   â””â”€â”€ ablation_*.pdf
â”‚   â””â”€â”€ NEURIPS_2025_PLAN.md        # ì´ íŒŒì¼
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baselines/
â”‚   â”‚   â”œâ”€â”€ infoshap_baseline.py
â”‚   â”‚   â”œâ”€â”€ permutation_baseline.py
â”‚   â”‚   â””â”€â”€ shap_variance_baseline.py
â”‚   â”œâ”€â”€ ablation/
â”‚   â”‚   â”œâ”€â”€ ablation_ensemble_size.py
â”‚   â”‚   â”œâ”€â”€ ablation_permutation_runs.py
â”‚   â”‚   â”œâ”€â”€ ablation_sample_size.py
â”‚   â”‚   â””â”€â”€ ablation_subsampling.py
â”‚   â””â”€â”€ large_scale/
â”‚       â”œâ”€â”€ experiment_10k.py
â”‚       â””â”€â”€ experiment_additional_datasets.py
â”‚
â””â”€â”€ chorok/v3_fk_risk_attribution/  # ê¸°ì¡´ ì½”ë“œ
```

---

## ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

| ë¦¬ìŠ¤í¬ | í™•ë¥  | ëŒ€ì‘ |
|--------|------|------|
| InfoSHAPì´ ìš°ë¦¬ë³´ë‹¤ ë‚˜ìŒ | ë‚®ìŒ | Actionabilityë¡œ ì°¨ë³„í™” |
| Theory ì¦ëª… ì‹¤íŒ¨ | ì¤‘ê°„ | Empirical focusë¡œ ì „í™˜ |
| ëŒ€ê·œëª¨ ì‹¤í—˜ ì‹œê°„ ë¶€ì¡± | ì¤‘ê°„ | n=10000ê¹Œì§€ë§Œ, ë‚˜ë¨¸ì§€ appendix |
| Deadline miss | ë‚®ìŒ | KDD 2026ìœ¼ë¡œ ì „í™˜ |

---

## ë‹¤ìŒ ì•¡ì…˜

1. **ì§€ê¸ˆ ë‹¹ì¥**: Baselines êµ¬í˜„ ì‹œì‘ (InfoSHAP ë¨¼ì €)
2. **ì´ë²ˆ ì£¼**: Ablation ì‹¤í—˜ ì„¤ê³„ ë° ì½”ë“œ ì‘ì„±
3. **ì§€ë„êµìˆ˜ ë¯¸íŒ…**: ì´ ê³„íš ê³µìœ , Theory ë°©í–¥ ì¡°ì–¸ ìš”ì²­

---

*ìƒì„±ì¼: 2025-11-29*
*ë§ˆì§€ë§‰ ìˆ˜ì •: 2025-11-29*
