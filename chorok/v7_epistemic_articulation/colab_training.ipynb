{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Epistemic Articulation Training\n",
        "\n",
        "**Before running:** Go to Runtime → Change runtime type → Select T4 GPU"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Clone repo\n",
        "!git clone https://github.com/ChorokLeeDev/ai-in-finance.git\n",
        "%cd ai-in-finance/chorok/v7_epistemic_articulation"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Install dependencies\n",
        "!pip install -q transformers accelerate trl peft datasets bitsandbytes"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Check GPU\n",
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Quick validation test (proves entropy works)\n",
        "!python quick_test_v3.py"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Generate DPO dataset with GPT-2 (fast, ~2 min)\n",
        "!python generate_dataset.py"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train with DPO (GPT-2, ~5 min)\n",
        "!python train_dpo.py --model gpt2 --dataset dpo_dataset.json --epochs 2"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluate trained model\n",
        "!python train_dpo.py --mode eval --model ./epistemic_model"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Optional: Train with Mistral-7B (better results, ~1 hour)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset with Mistral (better quality pairs)\n",
        "# !python generate_dataset_llama.py --model mistralai/Mistral-7B-Instruct-v0.2 --samples 5"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with Mistral\n",
        "# !python train_dpo.py --model mistralai/Mistral-7B-Instruct-v0.2 --dataset dpo_dataset_llama.json --epochs 2"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
